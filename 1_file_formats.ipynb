{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "py__imports"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import gzip\n",
    "import json\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Import Snowpark packages\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "snowflake_session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e10807-c07e-4e97-8eb1-64ac59409bb3",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": true,
    "language": "sql",
    "name": "sql__prepare_demo"
   },
   "outputs": [],
   "source": "use schema \"DEMO\";\ncreate or replace stage \"STG__DATA\";"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566cba3-d0b3-49bd-a4d7-61896bab7934",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "py__prepare_demo"
   },
   "outputs": [],
   "source": "snowflake_session.file.put(\"data/1.csv.gz\", '@\"STG__DATA\"/csv', overwrite=True)\nsnowflake_session.file.put(\"data/2.json.gz\", '@\"STG__DATA\"/json', overwrite=True)\nsnowflake_session.file.put(\"data/3.parquet\", '@\"STG__DATA\"/parquet', overwrite=True)"
  },
  {
   "cell_type": "code",
   "id": "99b59f11-2465-46fb-895b-7a2e29cd6a83",
   "metadata": {
    "language": "sql",
    "name": "sql__view_files"
   },
   "outputs": [],
   "source": "list @\"STG__DATA\";",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce93bd3-7da7-417a-8882-8a0ce0c918eb",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "py__file_formats__csv"
   },
   "outputs": [],
   "source": [
    "st.header(\"File Formats - CSV\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "  The typical file format that we're all familiar with.\n",
    "  \n",
    "  For our example, we have a pipe-delimited file of some basic event logging.\n",
    "\"\"\")\n",
    "\n",
    "file_path__csv = r\"data/1.csv.gz\"\n",
    "with gzip.open(file_path__csv, \"rt\") as csv_file:\n",
    "  st.code(csv_file.read(), language=\"csv\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "  The file format here is fairly simple, however we leverage two options that are less standard:\n",
    "\n",
    "    - parse_header: Key option that ensures the first header is leveraged as a header when parsing metadata\n",
    "    - error_on_column_count_mismatch: Option that allows files to have missing/new columns compared to the destination table\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "sql__file_formats__csv"
   },
   "outputs": [],
   "source": [
    "create or replace file format \"FF_CSV\"\n",
    "  type = CSV\n",
    "  field_delimiter = '|'\n",
    "  parse_header = TRUE\n",
    "  error_on_column_count_mismatch = FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "py__file_formats__json"
   },
   "outputs": [],
   "source": [
    "st.header(\"File Formats - JSON\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "  The typical semi-structured file format that most of us are familiar with.\n",
    "  \n",
    "  For our example, we have a file with some more basic event logging.\n",
    "\"\"\")\n",
    "\n",
    "file_path__json = r\"data/2.json.gz\"\n",
    "with gzip.open(file_path__json, \"rt\") as json_file:\n",
    "  json_string = json_file.read()\n",
    "  json_data = json.loads(json_string)\n",
    "  json_pretty = json.dumps(json_data, indent = 2)\n",
    "    \n",
    "st.code(json_pretty, language=\"json\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "  The file format here is more simple than for CSVs, however we leverage one options that is worth explaining:\n",
    "\n",
    "    - strip_outer_array: Reads each element as its own record instead of reading the entire file into a single record\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48715241-a599-42bf-9537-357d2a046f75",
   "metadata": {
    "language": "sql",
    "name": "sql__file_formats__json"
   },
   "outputs": [],
   "source": [
    "create or replace file format \"FF_JSON\"\n",
    "  type = JSON\n",
    "  strip_outer_array = TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab06e67-5293-4204-aac7-f05c823633db",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "py__file_formats__parquet"
   },
   "outputs": [],
   "source": [
    "st.header(\"File Formats - Parquet\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "  The common optimised semi-structured file format that many of us are familiar with.\n",
    "  \n",
    "  For our example, we have a file with some more basic event logging.\n",
    "\"\"\")\n",
    "\n",
    "file_path__parquet = r\"data/3.parquet\"\n",
    "parquet_data = pq.read_table(file_path__parquet)\n",
    "    \n",
    "st.code(parquet_data, language=\"parquet\")\n",
    "\n",
    "st.markdown(\"The file format here is the most simple of our examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b20aa-6591-4798-841d-2887b3f6da5c",
   "metadata": {
    "language": "sql",
    "name": "sql__file_formats__parquet"
   },
   "outputs": [],
   "source": [
    "create or replace file format \"FF_PARQUET\"\n",
    "  type = PARQUET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde1b6b-1663-40f9-bf15-96f8c85480a4",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "py__file_formats__summary"
   },
   "outputs": [],
   "source": [
    "st.header(\"File Formats - Summary\")\n",
    "\n",
    "st.markdown(\"So we have three file formats:\")\n",
    "\n",
    "ff_col_csv, ff_col_json, ff_col_parquet = st.columns(3, gap=\"large\")\n",
    "with ff_col_csv:\n",
    "  st.subheader(\"CSV\")\n",
    "  st.code(sql__file_formats__csv.__getattribute__(\"query_executed\"), \"sql\")\n",
    "with ff_col_json:\n",
    "  st.subheader(\"JSON\")\n",
    "  st.code(sql__file_formats__json.__getattribute__(\"query_executed\"), \"sql\")\n",
    "with ff_col_parquet:\n",
    "  st.subheader(\"Parquet\")\n",
    "  st.code(sql__file_formats__parquet.__getattribute__(\"query_executed\"), \"sql\")"
   ]
  }
 ]
}